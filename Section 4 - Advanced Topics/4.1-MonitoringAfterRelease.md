# Monitoring Databases After Release

Many DBAs and operational staff have tools in place to monitor their database instances. These might be homegrown tools, third party tools, or perhaps just peridic checks of Performance Monitor data. No matter what method you choose, it is important to have some sort of tooling in place to gather metrics about the performance of your database. 

Note: If you do not monitor the performance of your database, start now.

## Monitoring Metrics
Many organizations monitor the traditional physical resources of their database, such as CPU, memory, disk IO, network bandwidth, and more. For many databases, there are also important higher level metrics such as transaction counts, batches sizes, blocking, etc. There are numerous lists available from Data Platform MVPs about which counters to monitor. You should ensure that you are baselining and capturing these metrics.

In order to improve the value you get from your database and the code you deploy, you should also include business level metrics that let you know how the various entities in your database are being used. For example, in our Parts Unlimited database, we have a series of orders. We might want to track the rate of orders made over time. We may want to know how many carts are created in the database compared to how many orders we insert (a measure of shoppers abandoning their carts). These are the types of business metrics that can be easily gathered from a database, and are often measured in other systems, perhaps from reports in our application or in a downstream data warehouse.

These metrics are also useful from an application and database development perspective, where we can measure the impact of our code changes. If we receive less orders, is this because of a slowdown in our system, perhaps new application code or database referential integrity code is slowing things down? Are more low level errors, like foreign key errors being reported to the application, and subsequently the users who decided to shop elsewhere rather than correct an issue? 

We can't necessarily program the system to make these decisions, but by including metrics from our application and our database, we can more quickly determine the potential cause of changes. What's more, our monitoring system should be able to also display when various deployments were performed. This will help us determine if a particular change has caused a change in our metrics.

We aren't just looking for problems, however, we also want to determine if the features that we build into our software are being used. This means that we want to ensure that new code contains instrumentation to gather data when the code is run. This is also true in database code. SQL Server gives us Extended Events, which can be used to track activity for specific objects or code. We can use this to determine how our changes affect server performance, or even user behavior. This course won't go into Extended Events in detail, but I would urge you to examine how adding lightweight sessions to your SQL Server instances can give you additional instrumentation that is invaluable in measuring your database performance.

The Application Insights platform is included in Azure, and I would urge you to extend the data collection to your database. If you use a third party tool, ensure it can be extended to incorporate business level metrics that can help to pinpoint potential issues resulting from the rapid changes of your codebase.

The last part of performance should be obvious in a DevOps world, but far too many organizations don't take advantage of their monitoring data. Any trends, patterns, or observations from operations staff should be fed back to developers. No matter whether the data appears to be positive or negative, the collaboration of everyone is important to driving future decisions about what code to write, and how to write it.
